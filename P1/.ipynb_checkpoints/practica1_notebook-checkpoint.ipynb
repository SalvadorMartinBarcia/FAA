{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos las librerias tanto del sklearn como las nuestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Clasificador\n",
    "import EstrategiaParticionado\n",
    "from Datos import Datos\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos un programa de prueba para mostrar las comparaciones de las predicciones con nuestra implementacion del algoritmo y la de SKLEARN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion simple\n",
    "\n",
    "Primero, ejecutaremos nuestra implementación con validación simple, sin la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'EstrategiaParticionado' has no attribute 'ValidacionSimple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d0a8b4ce8433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/tic-tac-toe.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestrategia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstrategiaParticionado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValidacionSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclasificador\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClasificadorNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0merror_media_sin_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_std_sin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidacion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestrategia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasificador\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'EstrategiaParticionado' has no attribute 'ValidacionSimple'"
     ]
    }
   ],
   "source": [
    "dataset = Datos('data/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_t, error_std_sin = clasificador.validacion(estrategia, dataset, clasificador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecutamos sklearn con validación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1d7b4d1dec53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencAtributos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnominalAtributos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencAtributos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "print(Y)\n",
    "clf = MultinomialNB(alpha=0)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_t = 1 - accuracy_score(y_test, predicciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo ejecutaremos con la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.298429319372\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_t, error_std_con = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.317708333333\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_t = 1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente paso, ejecutamos lo anterior con el conjunto de datos 'german.data' y cambiando la variable 'clf' para que ejecute Naive Bayes con GaussianNB, ya que el conjunto 'german.data' contiene valores continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255639097744\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2825\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.240601503759\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2825\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)\n",
    "\n",
    "\n",
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_sin_t)\n",
    "salida += \"<td>%f</td></tr>\" % (error_sk_sin_t)\n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_con_t)\n",
    "salida += \"<td>%f</td></tr></table>\" % (error_sk_con_t)\n",
    "\n",
    "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_sin_g)\n",
    "salida2 += \"<td>%f</td></tr>\" % (error_sk_sin_g)\n",
    "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_con_g)\n",
    "salida2 += \"<td>%f</td></tr></table>\" % (error_sk_con_g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN DE DATOS\n",
    "\n",
    "Vamos a representar mediante tablas los distintas tasas de error obtenidas\n",
    "##### Tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.290576</td><td>0.312500</td></tr><tr><td>NB con Laplace</td><td>0.298429</td><td>0.317708</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar los datos son muy parejo, por tanto no se podria considerar la implementacion mejor que la oficial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.255639</td><td>0.282500</td></tr><tr><td>NB con Laplace</td><td>0.240602</td><td>0.282500</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML(salida2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hay mas diferencia entre nuestra implementacion y la de Sklearn, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
    "\n",
    "Hasta ahora, hemos ejecutado la validación simple. A continuación ejecutaremos los mismos ejemplos con validación cruzada.\n",
    "\n",
    "## Validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.301052631579 0.0593967830723\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_t, error_std_sin_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_t, error_std_sin_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335916531018 0.0867089672528\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = MultinomialNB(0)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_sin_t = 1 - score.mean()\n",
    "error_std_sk_sin_t = score.std()\n",
    "print error_media_sk_sin_t, error_std_sk_sin_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303684210526 0.0512746123591\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_t, error_std_con_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_t, error_std_con_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.334874864352 0.087666994993\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(1)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_con_t = 1 - score.mean()\n",
    "error_std_sk_con_t = score.std()\n",
    "print error_media_sk_con_t, error_std_sk_con_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ejecutamos lo anterior con el conjuento de datos 'german.data' y GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.243 0.0402616442784\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada() #por defecto, 10\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_g, error_std_sin_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_g, error_std_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_sin_g = 1 - score.mean()\n",
    "error_std_sk_sin_g = score.std()\n",
    "print error_media_sk_sin_g, error_std_sk_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2445 0.0372122291727\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_g, error_std_con_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_g, error_std_con_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_con_g = 1 - score.mean()\n",
    "error_std_sk_con_g = score.std()\n",
    "print error_media_sk_con_g, error_std_sk_con_g\n",
    "\n",
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%.4f ± %.3f</td>\" % (error_media_sin_t,error_std_sin_t)\n",
    "salida += \"<td>%.4f ± %.3f</td></tr>\" % (error_media_sk_sin_t,error_std_sk_sin_t)\n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%.4f ± %.3f</td>\" % (error_media_con_t,error_std_con_t)\n",
    "salida += \"<td>%.4f ± %.3f</td></tr></table>\" % (error_media_sk_con_t,error_std_sk_con_t)\n",
    "\n",
    "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida2 += \"<td>%.4f ± %.3f</td>\" % (error_media_sin_g,error_std_sin_g)\n",
    "salida2 += \"<td>%.4f ± %.3f</td></tr>\" % (error_media_sk_sin_g,error_std_sk_sin_g)\n",
    "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
    "salida2 += \"<td>%.4f ± %.3f</td>\" % (error_media_con_g,error_std_con_g)\n",
    "salida2 += \"<td>%.4f ± %.3f</td></tr></table>\" % (error_media_sk_con_g,error_std_sk_con_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN DE DATOS\n",
    "\n",
    "Vamos a representar mediante tablas los distintas tasas medias de error y las desviaciones obtenidas.\n",
    "\n",
    "##### Tic-tac-toe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.3011 ± 0.059</td><td>0.3359 ± 0.087</td></tr><tr><td>NB con Laplace</td><td>0.3037 ± 0.051</td><td>0.3349 ± 0.088</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados como en el caso anterior la diferencia es de un 3% dependiendo de la ejecucion, por lo tanto no se puede decir que haya una mejor que otra.\n",
    "\n",
    "La desviación estandar, en nuestra implementación, mejora entorno a un 5% la de sklearn. Estos nos puede decir que nuestra implementación puede ser mejor que la de sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.2430 ± 0.040</td><td>0.2860 ± 0.034</td></tr><tr><td>NB con Laplace</td><td>0.2445 ± 0.037</td><td>0.2860 ± 0.034</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML(salida2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede observar que el porcentaje de error en nuestra implementación es más bajo. En torno al 8%. Como hemos comentado anteriormente, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
    "\n",
    "En este caso las desviaciones estandar son más bajas con la implementación de sklearn. Aproximadamente un 1%. Creemos que no se puede sacar una conclusión con un desvío de un 1%, esto puede ser a que los datos se calculan siguiendo una distribuición normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTA Estas mediciones pueden variar en las siguientes ejecuciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
