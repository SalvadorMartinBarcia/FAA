{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiR7BDzLYqZV"
   },
   "source": [
    "# **Fundamentos de Aprendizaje Automático**\n",
    "## Práctica 2: Vecinos próximos y Regresión logística\n",
    "### Grupo 1461, Ioana Caciula y Magdalena Herrera Soto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zJCktgHUZjYg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-460032df45ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: <encoding name> -*-\n",
    "from abc import ABCMeta,abstractmethod\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.stats import norm\n",
    "import collections\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOXdAWi8fPDA",
    "outputId": "f095688a-c360-4c70-b56a-f0c0371be86d"
   },
   "outputs": [],
   "source": [
    "dataset=Datos('./ConjuntosDatos/pima-indians-diabetes.data')\n",
    "particion = Particion()\n",
    "estrategia = ValidacionSimple()\n",
    "lista_p = estrategia.creaParticiones(dataset.datos)\n",
    "for ele in lista_p:\n",
    "    print(\"Indices train: \")\n",
    "    print(ele.indicesTrain)\n",
    "    print(\"Indices test: \")\n",
    "    print(ele.indicesTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGOTD7ThY-SD"
   },
   "source": [
    "## 1. Vecinos Próximos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etS_2XDCZTJ0"
   },
   "source": [
    "## 2. Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos los dos tipos de particionado para los dos conjuntos. Los resultados expresan la tasa de error/acierto, en concreto, el promedio de error para las distintas particiones, asi como su desviación típica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUpy_AqHaC8l"
   },
   "source": [
    "A continuación vamos a probar con el conjunto de datos pima-indians-diabetes.data y validación simple para el método de regresión logística con 50 épocas, una constante de aprendizaje igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k35N0pwZ1N-",
    "outputId": "275246c5-24a4-4eee-af29-6bb44da90512"
   },
   "outputs": [],
   "source": [
    "#Regresión Logística con datos diabetes\n",
    "dataset=Datos('./ConjuntosDatos/pima-indians-diabetes.data')\n",
    "p=Particion()\n",
    "print(\"\\nValidacion Simple:\")\n",
    "particion = ValidacionSimple(numeroEjecuciones=50)\n",
    "clasificador = ClasificadorRegresionLogistica(nEpocas=50)\n",
    "error = clasificador.validacion(particion,dataset,clasificador)\n",
    "vsdiabetes = error\n",
    "print(\"Media: \" + str([np.mean(error)]) + \"\\nDesviacion: \" + str([np.std(error)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSyRo364a8Bm"
   },
   "source": [
    "Comentar el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3HrWd1ZbBbi"
   },
   "source": [
    "Repetímos el proceso, esta vez con validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqKKEhAHZ6NA",
    "outputId": "6fa1568c-fb50-4421-cce0-d1c828709288"
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacion Cruzada:\")\n",
    "particion = ValidacionCruzada(4)\n",
    "clasificador = ClasificadorRegresionLogistica(nEpocas=50)\n",
    "error = clasificador.validacion(particion,dataset,clasificador)\n",
    "vcdiabetes = error\n",
    "print(\"Media: \" + str([np.mean(error)]) + \"\\nDesviacion: \" + str([np.std(error)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eH--81MbNHo"
   },
   "source": [
    "Comentar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWC3e0BUbMFu"
   },
   "source": [
    "Repetimos todo el proceso anterior, esta vez con el conjunto de datos wdbc.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kczov1m6Z8wY",
    "outputId": "23cfeee8-0c5c-4f6f-c959-6cec51ba5a59"
   },
   "outputs": [],
   "source": [
    "#Regresión Logistica con datos cancer\n",
    "dataset=Datos('./ConjuntosDatos/wdbc.data')\n",
    "print(\"\\nValidacionSimple:\")\n",
    "particion = ValidacionSimple(numeroEjecuciones=50)\n",
    "clasificador = ClasificadorRegresionLogistica(nEpocas=50)\n",
    "error = clasificador.validacion(particion,dataset,clasificador)\n",
    "vsbc = error\n",
    "print(\"Media: \" + str([np.mean(error)]) + \"\\nDesviacion: \" + str([np.std(error)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydrBEKAjbh2s"
   },
   "source": [
    "Validación cruzada con el segundo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d4VoFZrZ-sl",
    "outputId": "c4c82110-eb28-4a1e-a8cf-eb36e61daef0"
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacion Cruzada:\")\n",
    "particion = ValidacionCruzada(4)\n",
    "clasificador = ClasificadorRegresionLogistica(nEpocas=50)\n",
    "error = clasificador.validacion(particion,dataset,clasificador)\n",
    "vcbc = error\n",
    "print(\"Media: \" + str([np.mean(error)]) + \"\\nDesviacion: \" + str([np.std(error)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se representan en la siguiente tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tabulate([[\"V. Simple\", \n",
    "                   str(\"{0:.4f}\".format(np.mean(vsdiabetes)))+\" ± \"+str(\"{0:.4f}\".format(np.std(vsdiabetes))),\n",
    "                  str(\"{0:.4f}\".format(np.mean(vsbc)))+\" ± \"+str(\"{0:.4f}\".format(np.std(vsbc)))],\n",
    "                 [\"V. Cruzada\", \n",
    "                   str(\"{0:.4f}\".format(np.mean(vcdiabetes)))+\" ± \"+str(\"{0:.4f}\".format(np.std(vcdiabetes))),\n",
    "                   str(\"{0:.4f}\".format(np.mean(vcbc)))+\" ± \"+str(\"{0:.4f}\".format(np.std(vcbc)))]],\n",
    "    \n",
    "                [\"\", \"Cjto. Diabetes\", \"Cjto. Cáncer\"], \n",
    "                tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sns_wXldZXgl"
   },
   "source": [
    "## 3. Skikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecinos próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'datos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3b77db7ad976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/pima-indians-diabetes.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcruzada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_ohe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'datos'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/pima-indians-diabetes.data')\n",
    "simple = ShuffleSplit(len(dataset.datos), test_size=.30, train_size=0.7, random_state=0)\n",
    "cruzada = ShuffleSplit(n_splits=4)\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(dataset.datos[:,:-1])\n",
    "x=x.astype('float')\n",
    "y = dataset.datos[:,-1]\n",
    "y=y.astype('float')\n",
    "\n",
    "\n",
    "print(\"Validacion cruzada con Distancia Euclidea:\")\n",
    "clasificador = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "euclidea_1 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "print(\"Validacion cruzada con Distancia de Manhattan:\")\n",
    "clasificador = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "manhattan_1 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "print(\"Validacion simple con Distancia de Mahalanobis:\\nIMPLEMENTAR????\\n\")\n",
    "#clasificador = KNeighborsClassifier(n_neighbors=5, metric='mahalanobis', metric_params={'V': np.cov(ct)})\n",
    "#Hay que pasarle a V el vctor o matriz de covarianza?????\n",
    "\n",
    "#covarianza = np.cov(x.astype(float))\n",
    "#clasificador = KNeighborsClassifier(n_neighbors=5, metric='mahalanobis', metric_params={'V': covarianza})\n",
    "\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "mahalanobis_1 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('data/wdbc.data')\n",
    "simple = ShuffleSplit(len(dataset.datos), test_size=.30, train_size=0.7, random_state=0)\n",
    "cruzada = ShuffleSplit(n_splits=4)\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(dataset.datos[:,:-1])\n",
    "x=x.astype('float')\n",
    "y = dataset.datos[:,-1]\n",
    "y=y.astype('float')\n",
    "\n",
    "\n",
    "print(\"Validacion cruzada con Distancia Euclidea:\")\n",
    "clasificador = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "euclidea_2 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "print(\"Validacion cruzada con Distancia de Manhattan:\")\n",
    "clasificador = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "manhattan_2 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "print(\"Validacion simple con Distancia de Mahalanobis:\\nIMPLEMENTAR????\\n\")\n",
    "#clasificador = KNeighborsClassifier(n_neighbors=5, metric='mahalanobis', metric_params={'V': np.cov(ct)})\n",
    "#Hay que pasarle a V el vctor o matriz de covarianza?????\n",
    "\n",
    "#covarianza = np.cov(x.astype(float))\n",
    "#clasificador = KNeighborsClassifier(n_neighbors=5, metric='mahalanobis', metric_params={'V': covarianza})\n",
    "\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "mahalanobis_2 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tabulate([\n",
    "    [\"Dist. Euclidea\", \n",
    "        str(\"{0:.4f}\".format(1-np.mean(euclidea_1)))+\" ± \"+str(\"{0:.4f}\".format(np.std(euclidea_1))),\n",
    "        str(\"{0:.4f}\".format(1-np.mean(euclidea_2)))+\" ± \"+str(\"{0:.4f}\".format(np.std(euclidea_2)))\n",
    "    ],\n",
    "    [\"Dist. Manhattan\", \n",
    "        str(\"{0:.4f}\".format(1-np.mean(manhattan_1)))+\" ± \"+str(\"{0:.4f}\".format(np.std(manhattan_1))),\n",
    "        str(\"{0:.4f}\".format(1-np.mean(manhattan_2)))+\" ± \"+str(\"{0:.4f}\".format(np.std(manhattan_2)))\n",
    "    ],\n",
    "    [\"Dist. Mahalanobis\", \n",
    "        str(\"{0:.4f}\".format(1-np.mean(mahalanobis_1)))+\" ± \"+str(\"{0:.4f}\".format(np.std(mahalanobis_1))),\n",
    "        str(\"{0:.4f}\".format(1-np.mean(mahalanobis_2)))+\" ± \"+str(\"{0:.4f}\".format(np.std(mahalanobis_2)))]\n",
    "    ],\n",
    "    [\"\", \"Cjto. Diabetes\", \"Cjto. Cáncer\"], \n",
    "    tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('data/pima-indians-diabetes.data')\n",
    "simple = ShuffleSplit(len(dataset.datos), test_size=.30, train_size=0.7, random_state=0)\n",
    "cruzada = ShuffleSplit(n_splits=4)\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(dataset.datos[:,:-1])\n",
    "x=x.astype('float')\n",
    "y = dataset.datos[:,-1]\n",
    "y=y.astype('float')\n",
    "\n",
    "clasificador = LogisticRegression(random_state=0, max_iter=50)\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "rl_1 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "\n",
    "clasificador = make_pipeline(StandardScaler(), SGDClassifier(max_iter=50, learning_rate = 'constant', eta0=1))\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "sgd_1 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('data/wdbc.data')\n",
    "simple = ShuffleSplit(len(dataset.datos), test_size=.30, train_size=0.7, random_state=0)\n",
    "cruzada = ShuffleSplit(n_splits=4)\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(dataset.datos[:,:-1])\n",
    "x=x.astype('float')\n",
    "y = dataset.datos[:,-1]\n",
    "\n",
    "clasificador = LogisticRegression(random_state=0, max_iter=50)\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "rl_2 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n",
    "\n",
    "clasificador = make_pipeline(StandardScaler(), SGDClassifier(max_iter=50, learning_rate = 'constant', eta0=1))\n",
    "clasificador.fit(x, y)\n",
    "res = cross_val_score(clasificador, x, y, cv=simple)\n",
    "sgd_2 = res\n",
    "print(\"Media: \" + str(1-np.mean((res))) + \"\\nDesviacion: \"+ str(np.std((res))) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_j9NGO1Zdzb"
   },
   "source": [
    "## 4. Análisis ROC\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MemoriaP2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
