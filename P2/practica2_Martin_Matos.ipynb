{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"text-align:center;\" class=\"centrado\"> Prácticas FAA: Salvador Martín Barcia y Patricia Matos Meza </h2>\n",
    "<h3 style=\"text-align:center;\" class=\"centrado\"> Práctica 2: Modelos, Scikit-learn, Análisis ROC </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium;\"> A continuación, distribuiremos este cuaderno en los diferentes clasificadores que hemos implementado: Naive Bayes, Vecinos Próximos y Regresión Logística. Al final de cada una de ellas habrá un resumen de lo medido para que así sea más fácil ver los resultados. </p>\n",
    "\n",
    "<p style=\"font-size: medium;\"> Ahora, importaremos todas las librerías necesarias para la ejecución. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from ValidacionCruzada import ValidacionCruzada\n",
    "from ValidacionSimple import ValidacionSimple\n",
    "from ClasificadorNaiveBayes import ClasificadorNaiveBayes\n",
    "from ClasificadorVecinosProximos import ClasificadorVecinosProximos\n",
    "from ClasificadorRegresionLogistica import ClasificadorRegresionLogistica\n",
    "from sklearn import preprocessing, naive_bayes, model_selection, linear_model, neighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "from IPython.display import display\n",
    "\n",
    "# Ignoramos warnings porque al ejecutar scikit de regresión logística salta uno con epocas menores a 100\n",
    "# Y para tener tiempos de ejecución medianamente pequeños al compararlo con nuestra implementación\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instalamos el paquete dataframe_image que nos ayudará a plasmar los datos de manera más amigable\n",
    "import sys\n",
    "!conda install -c conda-forge --yes --prefix {sys.prefix} dataframe_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Obtención de los datos </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Para esta primera parte de la práctica, cogeremos los datos de nuestra implementación de la clase Datos. A diferencia de la práctica 1, utilizaremos dos nuevos conjuntos de datos proporcionados.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('data/pima-indians-diabetes.data')\n",
    "dataset2 = Datos('data/wdbc.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Naive-Bayes </h2>\n",
    "<p style=\"font-size: medium\"> Empezaremos con el clasificador Naive Bayes programado la práctica pasada. Ejecutaremos este clasificiador con las distintas estrategias de particionado también programadas en la práctica 1: Validación Simple y Validación Cruzada. No haremos hincapié en los comentarios de los resultados, puesto que este clasificador fue ya discutido en la práctica anterior.</p>\n",
    "<h3> Validación Simple </h3>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Simple con las funciones de la práctica anterior. </p>\n",
    "\n",
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30217391304347824\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple(0.4, 1)\n",
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "error_vs_sin_laplace_i_faa = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print(error_vs_sin_laplace_i_faa[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07941176470588235\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple(0.4, 1)\n",
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "error_vs_sin_laplace_w_faa = clasificador.validacion(estrategia, dataset2, clasificador)\n",
    "print(error_vs_sin_laplace_w_faa[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Indians      WDBC\n",
      "Errores  0.302174  0.079412\n"
     ]
    }
   ],
   "source": [
    "datos = [[error_vs_sin_laplace_i_faa[0], error_vs_sin_laplace_w_faa[0] ]]\n",
    "resumen = pd.DataFrame(datos, index=['Errores'],columns=['Indians', 'WDBC'])\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validación Cruzada </h3>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Cruzada con las funciones programas en esta práctica. </p>\n",
    "\n",
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particion 1 : 0.265625\n",
      "Particion 2 : 0.21875\n",
      "Particion 3 : 0.2708333333333333\n",
      "Particion 4 : 0.2916666666666667\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada(4)\n",
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "error_vc_sin_laplace_i_faa = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "\n",
    "for i, error in enumerate(error_vc_sin_laplace_i_faa):\n",
    "    print('Particion', i+1, ':', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particion 1 : 0.07042253521126761\n",
      "Particion 2 : 0.04929577464788732\n",
      "Particion 3 : 0.08450704225352113\n",
      "Particion 4 : 0.06993006993006994\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada(4)\n",
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "error_vc_sin_laplace_w_faa = clasificador.validacion(estrategia, dataset2, clasificador)\n",
    "\n",
    "for i, error in enumerate(error_vc_sin_laplace_w_faa):\n",
    "    print('Particion', i+1, ':', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Particion 1  Particion 2  Particion 3   Particion 4\n",
      "Indians     0.265625     0.218750     0.270833      0.291667\n",
      "WDBC        0.070423     0.049296     0.084507      0.069930\n"
     ]
    }
   ],
   "source": [
    "datos = [error_vc_sin_laplace_i_faa, error_vc_sin_laplace_w_faa]\n",
    "resumen = pd.DataFrame(datos, columns=['Particion 1', 'Particion 2', 'Particion 3',' Particion 4'],index=['Indians', 'WDBC'])\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Regresión Logística </h2>\n",
    "\n",
    "<p style=\"font-size: medium\">A continuación, mostraremos los valores que hemos seleccionado para probar el clasficador con valores distintos de épocas y constante de aprendizaje.</p>\n",
    "<p style=\"font-size: medium\">En el caso de las épocas hemos escogido números medianamente grandes para poder ver las diferencias con más claridad, y a su vez, que no aumentase demasiado el tiempo de ejecución. En cuanto a las constantes de aprendizaje, hemos seleccionado tanto valores grandes (10 y 1) como valores pequeños (0.1 y 0.01), de tal manera de evaluar el cambio de la frontera y su precisión respecto al mismo. Como sabemos, la frontera cambiará más bruscamente o más precisamente de acuerdo al valor de la constante. Evaluaremos también ventajas y desventajas que trae cada valor.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = [10, 20, 50]\n",
    "cAprendizajes = [10, 1, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validación Simple </h3>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Simple con las funciones programas en esta práctica. Obtendremos un resultado por constante de aprendizaje para cada una de las épocas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30869565217391304, 0.2782608695652174, 0.25, 0.23043478260869565], [0.35, 0.3652173913043478, 0.22391304347826088, 0.22608695652173913], [0.29347826086956524, 0.30869565217391304, 0.2891304347826087, 0.2565217391304348]]\n"
     ]
    }
   ],
   "source": [
    "data_rl_vs_i = []\n",
    "error_vs_sin_laplace_i_faa_rl = [] \n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        estrategia = ValidacionSimple(0.4, 1)\n",
    "        clasificador = ClasificadorRegresionLogistica(epoca, n)\n",
    "        error_vs_sin_laplace_i_faa_rl.extend(clasificador.validacion(estrategia, dataset, clasificador))\n",
    "    data_rl_vs_i.append(error_vs_sin_laplace_i_faa_rl)\n",
    "    error_vs_sin_laplace_i_faa_rl = []\n",
    "print(data_rl_vs_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03823529411764706, 0.029411764705882353, 0.029411764705882353, 0.03235294117647059], [0.05588235294117647, 0.04411764705882353, 0.04411764705882353, 0.026470588235294117], [0.06470588235294118, 0.047058823529411764, 0.026470588235294117, 0.026470588235294117]]\n"
     ]
    }
   ],
   "source": [
    "data_rl_vs_g = []\n",
    "error_vs_sin_laplace_w_faa_rl = []\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        estrategia = ValidacionSimple(0.4, 1)\n",
    "        clasificador = ClasificadorRegresionLogistica(epoca, n)\n",
    "        error_vs_sin_laplace_w_faa_rl.extend(clasificador.validacion(estrategia, dataset2, clasificador))\n",
    "    data_rl_vs_g.append(error_vs_sin_laplace_w_faa_rl)\n",
    "    error_vs_sin_laplace_w_faa_rl = [] \n",
    "print(data_rl_vs_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, hemos utilizados Dataframes con gradientes para representar los resultados para cada uno de los conjuntos de datos, en donde, mientras más oscuros estén más elevados serán sus valores y mientras menos oscuros estén, pasará lo contrario.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Indians </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col0,#T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col1,#T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #61a7d2;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col2{\n",
       "            background-color:  #a9cfe5;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col3,#T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col2,#T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #3484bf;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col3{\n",
       "            background-color:  #cddff1;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #519ccc;\n",
       "            color:  #000000;\n",
       "        }#T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #5fa6d1;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.308696</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.278261</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.250000</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.230435</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.350000</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.365217</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.223913</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.226087</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.293478</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.308696</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.289130</td>\n",
       "                        <td id=\"T_3f6599b8_2f92_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.256522</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5f85c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_rl_vs_i, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Hemos obtenido como resultado valores bastante variados. Tenemos errores grandes, medios y pequeños. </p>\n",
    "<p style=\"font-size: medium\"> Para 10 y 20 épocas, vemos que los errores más grandes están para las constantes con valor 10, es decir la frontera se ajusta peor para la constante aprendizaje 10. El mejor caso sería, para ambas, el error para la constante de valor 0.01. Al ser un valor pequeños, quiere decir que la frontera va cambiando poco a poco, consiguiendo así un número mayor de coincidencias que los demás valores. Cabe destacar que, aunque el mejor valor sea ese, el resto también pueden ser consideranos como mejores, ya que el error es casi constante para estos números de épocas.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Finalmente, para 50 épocas, el error más alto es en la constante de valor 1, siguiendole el error de n = 10, mientras que el clasificador tiene un número de errores bajos para n = 0.01 y n = 0.1.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Podemos entonces concluir que para este conjunto de datos los valores para la constante de aprendizaje que más favorecen al modelo son los pequeños, es decir, en nuestro caso n = 0.1 y n = 0.01.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col0,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col0,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col1,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col2,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col3,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col2,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col3{\n",
       "            background-color:  #9ac8e0;\n",
       "            color:  #000000;\n",
       "        }#T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col1,#T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #63a8d3;\n",
       "            color:  #000000;\n",
       "        }#T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #6fb0d7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.038235</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.029412</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.029412</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.032353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.055882</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.044118</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.044118</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.026471</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.064706</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.047059</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.026471</td>\n",
       "                        <td id=\"T_3f72c3c2_2f92_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.026471</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5f2c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_rl_vs_g, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En comparación con el conjunto de datos anterior, hemos obtenido errores mucho más pequeños. Esto podría significar que el modelo de regresión lineal junto a la estrategia de particionado, se ajustan mejor a este dataset que al anterior.</p>\n",
    "<p style=\"font-size: medium\"> Podemos observar que se mantiene más o menos el mismo comportamiento que en el conjunto de datos de Indians. Sin embargo, en este caso los mejores valores no se encuentran en las constantes de menor valor, sino en las de la mitad, que son n =  1 y n = 0.1. Entonces, este grupo de datos necesita un ajuste de la frontera ni demasiado preciso, ni demasiado brusco.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validación Cruzada </h3>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Cruzada cambiando los valores de las épocas y de las constantes al igual que en Validación Simple. Por cada constante de aprendizaje, guardaremos la media de los errores de las particiones para simplificar la representación de los mismos. Los valores elegidos para las épocas y para las constantes de aprendizaje serán los mismos que para el apartado anterior.</p>\n",
    "\n",
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30338541666666663, 0.2786458333333333, 0.25390625, 0.22265625], [0.3684895833333333, 0.25520833333333337, 0.24088541666666666, 0.23177083333333334], [0.3046875, 0.3828125, 0.2513020833333333, 0.22526041666666666]]\n"
     ]
    }
   ],
   "source": [
    "data_rl_vc_i = []\n",
    "error_vc_sin_laplace_i_faa_rl = []\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        estrategia = ValidacionCruzada(4)\n",
    "        clasificador = ClasificadorRegresionLogistica(epoca, n)\n",
    "        error_vc_sin_laplace_i_faa_rl.append(np.mean(clasificador.validacion(estrategia, dataset, clasificador)))\n",
    "    data_rl_vc_i.append(error_vc_sin_laplace_i_faa_rl)\n",
    "    error_vc_sin_laplace_i_faa_rl = []\n",
    "print(data_rl_vc_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.033401457697232344, 0.045676154831084406, 0.02808283266029745, 0.02985570767260908], [0.033401457697232344, 0.04568846646311435, 0.03867083620604748, 0.0475228996355757], [0.04570077809514429, 0.04919728159164778, 0.038658524574017535, 0.029880330936668965]]\n"
     ]
    }
   ],
   "source": [
    "data_rl_vc_w = []\n",
    "error_vc_sin_laplace_w_faa_rl = []\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        estrategia = ValidacionCruzada(4)\n",
    "        clasificador = ClasificadorRegresionLogistica(epoca, n)\n",
    "        error_vc_sin_laplace_w_faa_rl.append(np.mean(clasificador.validacion(estrategia, dataset2, clasificador)))\n",
    "    data_rl_vc_w.append(error_vc_sin_laplace_w_faa_rl)\n",
    "    error_vc_sin_laplace_w_faa_rl = []\n",
    "print(data_rl_vc_w)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>\n",
    "<p style=\"font-size: medium\">A continuación, los datos agrupados en dataframes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Indians </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col0,#T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col0,#T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #539ecd;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col2{\n",
       "            background-color:  #8fc2de;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col3,#T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col3,#T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #b7d4ea;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #c7dcef;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #75b4d8;\n",
       "            color:  #000000;\n",
       "        }#T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #b8d5ea;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.303385</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.278646</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.253906</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.222656</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.368490</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.255208</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.240885</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.231771</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.304688</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.382812</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.251302</td>\n",
       "                        <td id=\"T_409ef7a6_2f93_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.225260</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5e9a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_rl_vc_i, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> El comportamiento de los errores es similar al comportamiento del mismo dataset pero en validación simple. Los errores más altos se correspondes con los valores más altos de constante, y los mínimos se corresponden a los valores mínimos de n. </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Por otro lado, como esperábamos, los errores máximos son más pequeños que los errores máximos de Validación Simple, ya que Validación Cruzada hace una separación de los datos más exhaustiva que permite que la evaluación sea más certera que en la estrategia de particionado anterior. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col0{\n",
       "            background-color:  #a0cbe2;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col1,#T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col3,#T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col2,#T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col0,#T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col3{\n",
       "            background-color:  #c2d9ee;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #3787c0;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #92c4de;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #3e8ec4;\n",
       "            color:  #000000;\n",
       "        }#T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #81badb;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.033401</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.045676</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.028083</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.029856</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.033401</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.045688</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.038671</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.047523</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.045701</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.049197</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.038659</td>\n",
       "                        <td id=\"T_40a5bac8_2f93_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.029880</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5f2ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_rl_vc_w, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> El comportamiento de los errores cambia un poco en comparación al de validación simple. La magnitud de los errores está dispersa por los distintos valores, es decir, no hay un patrón claro. </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> La mayor concentración de errores grandes está para las constantes de valor elevado. Sin embargo, para las épocas de 20 y de 50, el error más pequeño se da para n = 0.01, en donde este es casi nulo. Mientras que, para la época de 10, este valor casi nulo se da para n = 0.1. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Vecinos próximos </h2>\n",
    "\n",
    "<p style=\"font-size: medium\">A continuación, mostraremos los valores que hemos seleccionado para probar el clasficador con valores distintos número de vecinos, algoritmo de distancia y normalización</p>\n",
    "<p style=\"font-size: medium\">Como tenemos que hacerlo para 3 distancias, mínimo 2 k, con normalización y sin ella, con las distintas estrategias de particionado y para ambas bases de datos deberíamos ejecutar la práctica mínimo 48 veces. Como esto nos llevaría demasiado tiempo, ejecutaremos solo algunos de los casos, reduciendo asi en gran medida el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksKnn = [1 ,3, 5]\n",
    "distanciasKnn = [\"euclidea\", \"manhattan\", \"mahalanobis\"]\n",
    "normalizacionKnn = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validación Simple </h3>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Simple para ambas k, con la distancia euclidea, con normalización y sin ella\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29694323144104806, 0.25327510917030566, 0.2314410480349345], [0.35807860262008734, 0.31004366812227074, 0.2576419213973799]]\n"
     ]
    }
   ],
   "source": [
    "data_knn_vs_i = []\n",
    "error_vs_i_knn = [] \n",
    "for n in normalizacionKnn:\n",
    "    for k in ksKnn:\n",
    "        estrategia = ValidacionSimple(0.7, 1)\n",
    "        clasificador = ClasificadorVecinosProximos(k=k, normalizacion=n)\n",
    "        error_vs_i_knn.extend(clasificador.validacion(estrategia, dataset, clasificador))\n",
    "    data_knn_vs_i.append(error_vs_i_knn)\n",
    "    error_vs_i_knn = [] \n",
    "print(data_knn_vs_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03529411764705882, 0.041176470588235294, 0.023529411764705882], [0.08823529411764706, 0.07647058823529412, 0.08235294117647059]]\n"
     ]
    }
   ],
   "source": [
    "data_knn_vs_wdbc = []\n",
    "error_vs_wdbc_knn = [] \n",
    "for n in normalizacionKnn:\n",
    "    for k in ksKnn:\n",
    "        estrategia = ValidacionSimple(0.7, 1)\n",
    "        clasificador = ClasificadorVecinosProximos(k=k, normalizacion=n)\n",
    "        error_vs_wdbc_knn.extend(clasificador.validacion(estrategia, dataset2, clasificador))\n",
    "    data_knn_vs_wdbc.append(error_vs_wdbc_knn)\n",
    "    error_vs_wdbc_knn = [] \n",
    "print(data_knn_vs_wdbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, los datos agrupados en Dataframes. Cabe destacar, que hemos hecho pruebas con datos normalizados y no normalizados, con diferentes valores para k, pero solo para la distancia euclídea, puesto que si ejecutabamos las tres distancias el tiempo de ejecución sería muy alto.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Indians distancia euclidea</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col0,#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #9ac8e0;\n",
       "            color:  #000000;\n",
       "        }#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col2,#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #72b2d8;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 1</th>        <th class=\"col_heading level0 col1\" >k = 3</th>        <th class=\"col_heading level0 col2\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Normalizado</th>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.296943</td>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.253275</td>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.231441</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >No normalizado</th>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.358079</td>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.310044</td>\n",
       "                        <td id=\"T_dc4ec5f0_2f93_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.257642</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac6062320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_knn_vs_i, columns=['k = 1','k = 3', 'k = 5'],index=['Normalizado', 'No normalizado'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">Como primera observación tenemos que los valores son parecidos entre sí, independientemente de si los datos estén normalizados o no. En cuanto a las diferencias de acuerdo al tamaño de vecindario escogido, tenemos que el modelo es ligeramente más efectivo para k = 3. Es un poco peor para k = 1, lo cual tiene sentido ya que al ser un valor de k bajo, podría haber ruído en los resultados. Sin embargo, todos los valores son bastante buenos y casi no hay diferencia. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC distancia euclidea</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_dc531394_2f93_11eb_b020_6999629006a3row0_col0{\n",
       "            background-color:  #58a1cf;\n",
       "            color:  #000000;\n",
       "        }#T_dc531394_2f93_11eb_b020_6999629006a3row0_col1,#T_dc531394_2f93_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_dc531394_2f93_11eb_b020_6999629006a3row0_col2,#T_dc531394_2f93_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_dc531394_2f93_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #77b5d9;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_dc531394_2f93_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 1</th>        <th class=\"col_heading level0 col1\" >k = 3</th>        <th class=\"col_heading level0 col2\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_dc531394_2f93_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Normalizado</th>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.035294</td>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.041176</td>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.023529</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc531394_2f93_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >No normalizado</th>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.088235</td>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.076471</td>\n",
       "                        <td id=\"T_dc531394_2f93_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.082353</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ef8ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_knn_vs_wdbc, columns=['k = 1','k = 3', 'k = 5'],index=['Normalizado', 'No normalizado'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Para este dataset podemos ver claramente como si hay una diferencia considerable entre los errores de los datos normalizados y los no normalizados. El modelo falla menos con datos normalizados para cada uno de los valores de k escogidos. </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Dentro de los datos normalizados, vemos como nuevamente el resultado óptimo, y con diferencia, lo tenemos para k = 3, siendo casi nulo. Para el resto de k's, tenemos valores bastante parecidos. Por otra parte, dentro de los datos normalizados, destaca que el error más alto sea de k = 3 también. Esto puede deberse a que el ruído mencionado en el apartado anterior afecte más las clasificaciones de los datos no normalizados que a los normalizados y por ello los valores de los errores se distancien entre ellos y sean más elevados. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validación Cruzada </h3>\n",
    "<p style=\"font-size: medium\">Para la estrategia de Validación Cruzada utilizaremos dos tamaños de k, con normalización de los datos para los 3 algoritmos de distancias, debido al tiempo de ejecución elevado que tiene.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksKnn = [1, 5]\n",
    "distanciasKnn = [\"euclidea\", \"manhattan\", \"mahalanobis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2708333333333333]\n",
      "[0.2708333333333333, 0.2890625]\n",
      "[0.29036458333333337]\n",
      "[0.29036458333333337, 0.3059895833333333]\n",
      "[0.26822916666666663]\n",
      "[0.26822916666666663, 0.28125]\n",
      "[[0.2708333333333333, 0.2890625], [0.29036458333333337, 0.3059895833333333], [0.26822916666666663, 0.28125]]\n"
     ]
    }
   ],
   "source": [
    "data_knn_vc_i = []\n",
    "error_vc_i_knn = [] \n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        estrategia = ValidacionCruzada(4)\n",
    "        clasificador = ClasificadorVecinosProximos(k=3, distancia=dist)\n",
    "        error_vc_i_knn.append(np.mean(clasificador.validacion(estrategia, dataset, clasificador)))\n",
    "        print(error_vc_i_knn)\n",
    "    data_knn_vc_i.append(error_vc_i_knn)\n",
    "    error_vc_i_knn = []\n",
    "print(data_knn_vc_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03160395942086083]\n",
      "[0.03160395942086083, 0.03513739781345415]\n",
      "[0.026371515808135525]\n",
      "[0.026371515808135525, 0.028132079188417217]\n",
      "[0.17924505072392394]\n",
      "[0.17924505072392394, 0.19332955776617744]\n",
      "[[0.03160395942086083, 0.03513739781345415], [0.026371515808135525, 0.028132079188417217], [0.17924505072392394, 0.19332955776617744]]\n"
     ]
    }
   ],
   "source": [
    "data_knn_vc_wdbc = []\n",
    "error_vc_wdbc_knn = [] \n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        estrategia = ValidacionCruzada(4)\n",
    "        clasificador = ClasificadorVecinosProximos(k=3, distancia=dist)\n",
    "        error_vc_wdbc_knn.append(np.mean(clasificador.validacion(estrategia, dataset2, clasificador)))\n",
    "        print(error_vc_wdbc_knn)\n",
    "    data_knn_vc_wdbc.append(error_vc_wdbc_knn)\n",
    "    error_vc_wdbc_knn = []\n",
    "print(data_knn_vc_wdbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Resumen de lo medido </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Indians</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ea3c375c_2f97_11eb_b020_6999629006a3row0_col0,#T_ea3c375c_2f97_11eb_b020_6999629006a3row1_col0,#T_ea3c375c_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_ea3c375c_2f97_11eb_b020_6999629006a3row0_col1,#T_ea3c375c_2f97_11eb_b020_6999629006a3row1_col1,#T_ea3c375c_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 1</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.270833</td>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.289062</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.290365</td>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.305990</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >Mahalanobis</th>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.268229</td>\n",
       "                        <td id=\"T_ea3c375c_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.281250</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ef8940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_knn_vc_i, index=['Euclídea', 'Manhattan', 'Mahalanobis'],columns=['k = 1', 'k = 5'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Como podemos observar en la tabla, para las tres distancias escogidas, el error óptimo lo conseguimos casi siempre en k = 1, es decir, en el vecino más próximo. Sin embargo, las diferencias entre la anterior y k = 5 son casi nulas, podría considerarse incluso que son igual de efectivas.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En cuanto a la distancia que mejor clasifica, podríamos decir que está entre Mahalanobis y Euclídea, pero tenemos que tomar en cuenta que Mahalanobis es mucho más costosa que la distancia euclídea, por lo que, en nuestra opinión, le otorgaría el 'premio' a la distancia Euclídea.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ea41c3ac_2f97_11eb_b020_6999629006a3row0_col0,#T_ea41c3ac_2f97_11eb_b020_6999629006a3row1_col0,#T_ea41c3ac_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_ea41c3ac_2f97_11eb_b020_6999629006a3row0_col1,#T_ea41c3ac_2f97_11eb_b020_6999629006a3row1_col1,#T_ea41c3ac_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 1</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.031604</td>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.035137</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.026372</td>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.028132</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >Mahalanobis</th>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.179245</td>\n",
       "                        <td id=\"T_ea41c3ac_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.193330</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ef88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_knn_vc_wdbc, index=['Euclídea', 'Manhattan', 'Mahalanobis'],columns=['k = 1', 'k = 5'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Una vez más, si observamos la tabla, podemos observar que los errores mínimos están en la columna de k = 1, similiarmente al dataset de indians.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Sin embargo, a diferencia de indians, la distancia más efectiva sería la de Manhattan y con una separación sustancial de los valores, es decir, nos definitvamente mejor sobre las otras dos distancias.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En general, este modelo se ajusta más al dataset de WDBC ya que sus errores son casi nulos en comparación a los errores obtenidos en el dataset de indians. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Scikit-learn </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Obtención de los datos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/pima-indians-diabetes.data')\n",
    "dataset2 = pd.read_csv('data/wdbc.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">Preparamos los datos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedDataset = preprocessing.OneHotEncoder(sparse=False)\n",
    "x = dataset.iloc[:,:-1]\n",
    "x2 = dataset2.iloc[:,:-1]\n",
    "\n",
    "encodedDataset.fit(x)\n",
    "x_indians = encodedDataset.transform(x) #Cogemos todos los datos menos la columna de Class\n",
    "y_indians = dataset.iloc[:,-1]\n",
    "\n",
    "encodedDataset.fit(x2)\n",
    "x_wdbc = encodedDataset.transform(x2) #Cogemos todos los datos menos la columna de Class\n",
    "y_wdbc = dataset2.iloc[:,-1]\n",
    "\n",
    "epocas = [10, 20, 50]\n",
    "cAprendizajes = [10, 1, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Regresión Logística </h3>\n",
    "<p style=\"font-size: medium\"> Para la segunda parte de regresión logística, ejecutaremos los métodos que nos proporciona Scikit-learn para este modelo lineal: LogisticRegression y SGDClassifier. Al igual que en nuestra implementación, ejecuataremos para cada método distintos valores de las épocas y constante de aprendizaje, que serán los mismos que en el apartado anterior.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Validación Simple </h4>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Simple con las funciones proporcionadas en scikit-learn, tanto LogisticRegression como SGDClassifier. </p>\n",
    "\n",
    "<h5> Indians </h5>\n",
    "<p style=\"font-size: medium\">A continuación, utilizaremos el método LogisticRegression. En este método iremos cambiando solo el valor de las épocas puesto que LogisticRegression tiene su propio optimizador para las constantes de aprendizaje y va ajustándolas según considere. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vs_i_lg = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "        clasificador = linear_model.LogisticRegression(max_iter = epoca)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_indians, y_indians, test_size=0.4)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_i_lg.append(1 - accuracy_score(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de la época  10  =  0.32792207792207795\n",
      "Error de la época  20  =  0.2857142857142857\n",
      "Error de la época  50  =  0.3441558441558441\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(epocas):\n",
    "    print('Error de la época ', i, ' = ', error_vs_i_lg[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este caso, no podemos comentar sobre los valores de constante de aprendizaje adecuados, pero sí podemos ver claramente que tenemos un porcentaje de fallo menor con unos valores de 20 y 50 en las épocas que en el resto. Es curioso como el error se mantiene en ambas, esto podría deberse al optimizador de constante de aprendizaje del método.</p>\n",
    "    \n",
    "<p style=\"font-size: medium\">\n",
    "Por otro lado, no podemos comparar LogisticRegression con nuestra implementación ya que no manejamos las mismas variables y no tendría sentido intentar analizar cual funciona mejor. Sin embargo, más abajo lo compararemos con SGDClassifier.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, utilizaremos el método SGDClassifier. Aquí si que incluiremos tanto las épocas como las constantes de aprendizaje.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "error_vs_i_sgd = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        clasificador = linear_model.SGDClassifier(max_iter = epoca, learning_rate = 'constant', eta0 = n)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_indians, y_indians, test_size=0.4)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_i_sgd.append(1 - accuracy_score(y_test, predicciones))\n",
    "    data.append(error_vs_i_sgd)\n",
    "    error_vs_i_sgd = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Resumen de lo medido </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_eae2de40_2f97_11eb_b020_6999629006a3row0_col0,#T_eae2de40_2f97_11eb_b020_6999629006a3row1_col3,#T_eae2de40_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #4594c7;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row0_col2{\n",
       "            background-color:  #4d99ca;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row0_col3,#T_eae2de40_2f97_11eb_b020_6999629006a3row1_col1,#T_eae2de40_2f97_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #b3d3e8;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #c7dbef;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #539ecd;\n",
       "            color:  #000000;\n",
       "        }#T_eae2de40_2f97_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #4695c8;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_eae2de40_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eae2de40_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.383117</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.366883</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.363636</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.311688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eae2de40_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.360390</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.344156</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.350649</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.428571</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eae2de40_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.357143</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.370130</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.327922</td>\n",
       "                        <td id=\"T_eae2de40_2f97_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.360390</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcaf4294ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En el caso de SGD, podemos observar como, a pesar de que algunos datos varíen, la concentración de errores grandes está en constantes de valor alto, similar a como ocurre en nuestra implementación y con valores parecidos. No ha mejorado ni empeorado nuestra implementación para este conjunto de datos.  </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Los porcentajes de error bajos están más dispersos, y en general, se podría decir que el modelo se ajusta mejor en la época de 10 en las constantes pequeñas, y el resto en las n del medio (n = 1 y n = 0.1). </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En comparación con LogisticRegression, no hay una mejora evidente. En este método, tenemos muchas más medidas que en el método anterior, sin embargo, parecen estar en el mismo rango de valores. El único inconveniente que puede tener SGD con respecto a Logistic es que tenemos que elegir manualmente la constante de aprendizaje lo cual, si la elegimos bien, puede ser muy bueno o, si la elegimos mal, puede ser muy malo. Con LogisticRegression no correríamos ese riesgo ya que genera su propia constante hasta mantener un error óptimo, como fue mencionado anteriormente.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC </h5>\n",
    "<p style=\"font-size: medium\"><p style=\"font-size: medium\">A continuación, utilizaremos el método LogisticRegression. Recordemos que en este método no utilizaremos distintos valores de constante de aprendizaje puesto que utiliza su propio optimizador. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vs_w_lg = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "        clasificador = linear_model.LogisticRegression(max_iter = epoca, fit_intercept=True)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_wdbc, y_wdbc, test_size=0.4)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_w_lg.append(1 - accuracy_score(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Resumen de lo medido</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de la época  10  =  0.3464912280701754\n",
      "Error de la época  20  =  0.368421052631579\n",
      "Error de la época  50  =  0.3728070175438597\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(epocas):\n",
    "    print('Error de la época ', i, ' = ', error_vs_w_lg[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este método, como fue mencionado anteriormente, no podemos realizar muchas comparaciones debido a que va decidiendo sus propias constantes de aprendizaje según vaya viendo el algoritmo. Sin embargo, podemos mencionar que los errores son mucho más altos en comparación a nuestra implementación. En nuestro algoritmo obtenemos errores de 0.03 o menos, mientras que aquí los mismos se elevan a 0.3.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, utilizaremos de nuevo el método SGDClassifier. Aquí si que incluiremos tanto las épocas como las constantes de aprendizaje.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3026315789473685, 0.33333333333333337, 0.32456140350877194, 0.381578947368421], [0.39473684210526316, 0.35526315789473684, 0.39035087719298245, 0.368421052631579], [0.3464912280701754, 0.368421052631579, 0.3157894736842105, 0.36403508771929827]]\n"
     ]
    }
   ],
   "source": [
    "data_w = []\n",
    "error_vs_w_sgd = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        clasificador = linear_model.SGDClassifier(max_iter = epoca, learning_rate = 'constant', eta0 = n)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_wdbc, y_wdbc, test_size=0.4)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_w_sgd.append(1 - accuracy_score(y_test, predicciones))\n",
    "    data_w.append(error_vs_w_sgd)\n",
    "    error_vs_w_sgd = []\n",
    "print(data_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Resumen de lo medido </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col0,#T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col1,#T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #8fc2de;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col2{\n",
       "            background-color:  #a5cde3;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col3,#T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col0,#T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #3585bf;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col3{\n",
       "            background-color:  #9ac8e0;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #66abd4;\n",
       "            color:  #000000;\n",
       "        }#T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #3181bd;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.302632</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.333333</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.324561</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.381579</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.394737</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.355263</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.390351</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.368421</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.346491</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.368421</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.315789</td>\n",
       "                        <td id=\"T_ec99fc46_2f97_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.364035</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5f26e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_w, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este caso, podemos observar como los porcentajes de error eleavados se encuentran más que todo en las n pequeñas, es decir, quizás la frontera que se ajusta a este modelo cambie bruscamente y por ello las n de menor valor se queden atrás.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Cabe destacar también, al igual que en LogisticRegression, los valores de error son mucho más grandes que en nuestra implementación. Esto podría deberse a que no estamos utilizando un valor de épocas lo suficientemente grande como para que el modelo pueda ajustarse correctamente. En otras palabras, puede que nuestra implementación se ajuste más rápidamente al modelo, mientras que el algoritmo de Sckit necesite más épocas para llegar a un error lo más mínimo posible.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Validación Cruzada </h4>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Cruzada con las funciones proporcionadas en scikit-learn. </p>\n",
    "\n",
    "\n",
    "<h5> Indians </h5>\n",
    "<p style=\"font-size: medium\">A continuación, lo haremos con el método LogisticRegression.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = [10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoca in epocas:\n",
    "    clasificador = linear_model.LogisticRegression(max_iter = epoca, fit_intercept=True)\n",
    "    cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "    error_vc_i_lr = 1 - model_selection.cross_val_score(clasificador, x_indians, y_indians, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de la época  10  =  0.3246753246753247\n",
      "Error de la época  20  =  0.3116883116883117\n",
      "Error de la época  50  =  0.3116883116883117\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(epocas):\n",
    "    print('Error de la época ', i, ' = ', error_vc_i_lr[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Los errores obtenidos para cada época son ligeramente más elevados que en nuestra implementación, pero están en el mismo rango y no hay diferencias que sean triviales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">Ahora, utilizaremos SGDClassifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i_vc = []\n",
    "error_vc_i_sgd = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        clasificador = linear_model.SGDClassifier(max_iter = epoca, learning_rate = 'constant', eta0 = n)\n",
    "        cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "        error = 1 - model_selection.cross_val_score(clasificador, x_indians, y_indians, cv=cv)\n",
    "        error_vc_i_sgd.append(np.mean(error.tolist())) # Hacemos la media para poder resumir los resultados facilmente\n",
    "    data_i_vc.append(error_vc_i_sgd)\n",
    "    error_vc_i_sgd = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col0{\n",
       "            background-color:  #add0e6;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col1{\n",
       "            background-color:  #7fb9da;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col2,#T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col0,#T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col3,#T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col2,#T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #87bddc;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col3{\n",
       "            background-color:  #a8cee4;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #a6cee4;\n",
       "            color:  #000000;\n",
       "        }#T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #77b5d9;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.331169</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.350649</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.396104</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.311688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.379870</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.344156</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.318182</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.334416</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.337662</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.399351</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.314935</td>\n",
       "                        <td id=\"T_ee6c7db4_2f97_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.357143</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5f95240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_i_vc, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este caso, vemos como los errores óptimos ocurren solo para el valor de 0.01 de la constante de aprendizaje. Se ajustan bastante a los valores obtenidos en nuestra implementación. La única diferencia sería que el tiempo de ejecución es ligeramente mayor en scikit, pero no demasiado como para influir de alguna manera.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC </h4>\n",
    "<p style=\"font-size: medium\">A continuación, lo haremos con el método LogisticRegression.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoca in epocas:\n",
    "    clasificador = linear_model.LogisticRegression(max_iter = epoca, fit_intercept=True)\n",
    "    cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "    error_vc_w_lr = 1 - model_selection.cross_val_score(clasificador, x_wdbc, y_wdbc, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de la época  10  =  0.42105263157894735\n",
      "Error de la época  20  =  0.368421052631579\n",
      "Error de la época  50  =  0.2807017543859649\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(epocas):\n",
    "    print('Error de la época ', i, ' = ', error_vc_w_lr[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Podemos observar que en validación cruzada también se obtienen valores sustancialmente grandes en comparación con nuestro algoritmo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">Ahora, lo haremos con el método SGDClassifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_vc = []\n",
    "error_vc_w_sgd = []\n",
    "# Comprobaremos los métodos para distintos valores de N y de épocas\n",
    "for epoca in epocas:\n",
    "    for n in cAprendizajes:\n",
    "        clasificador = linear_model.SGDClassifier(max_iter = epoca, learning_rate = 'constant', eta0 = n)\n",
    "        cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "        error = 1 - model_selection.cross_val_score(clasificador, x_wdbc, y_wdbc, cv=cv)\n",
    "        error_vc_w_sgd.append(np.mean(error.tolist())) # Hacemos la media para poder resumir los resultados facilmente\n",
    "    data_w_vc.append(error_vc_w_sgd)\n",
    "    error_vc_w_sgd = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_f794340e_2f97_11eb_b020_6999629006a3row0_col0,#T_f794340e_2f97_11eb_b020_6999629006a3row0_col2,#T_f794340e_2f97_11eb_b020_6999629006a3row1_col3,#T_f794340e_2f97_11eb_b020_6999629006a3row2_col3{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_f794340e_2f97_11eb_b020_6999629006a3row0_col1,#T_f794340e_2f97_11eb_b020_6999629006a3row1_col0,#T_f794340e_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_f794340e_2f97_11eb_b020_6999629006a3row0_col3{\n",
       "            background-color:  #5ba3d0;\n",
       "            color:  #000000;\n",
       "        }#T_f794340e_2f97_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #4695c8;\n",
       "            color:  #000000;\n",
       "        }#T_f794340e_2f97_11eb_b020_6999629006a3row1_col2{\n",
       "            background-color:  #2e7ebc;\n",
       "            color:  #000000;\n",
       "        }#T_f794340e_2f97_11eb_b020_6999629006a3row2_col0,#T_f794340e_2f97_11eb_b020_6999629006a3row2_col2{\n",
       "            background-color:  #58a1cf;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f794340e_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >n = 10</th>        <th class=\"col_heading level0 col1\" >n = 1</th>        <th class=\"col_heading level0 col2\" >n = 0.1</th>        <th class=\"col_heading level0 col3\" > n = 0.01</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f794340e_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >epoca = 10</th>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.390351</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.315789</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row0_col2\" class=\"data row0 col2\" >0.390351</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row0_col3\" class=\"data row0 col3\" >0.364035</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f794340e_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >epoca = 20</th>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.320175</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.377193</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row1_col2\" class=\"data row1 col2\" >0.390351</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row1_col3\" class=\"data row1 col3\" >0.394737</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f794340e_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >epoca = 50</th>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.377193</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.350877</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row2_col2\" class=\"data row2 col2\" >0.377193</td>\n",
       "                        <td id=\"T_f794340e_2f97_11eb_b020_6999629006a3row2_col3\" class=\"data row2 col3\" >0.390351</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ef8320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_w_vc, columns=['n = 10', 'n = 1', 'n = 0.1',' n = 0.01'],index=['epoca = 10', 'epoca = 20', 'epoca = 50'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este caso, de nuevo no hay ningún patrón establecido, pero podemos destacar que los errores bajos aparecen mayoritariamente paras la n de mayor valor. Una vez más, observamos que los valores son mucho mayores a los de nuestra implementación.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Para las n pequeñas, el error se dispara un poco y llega hasta 0.4. Esto podría también deberse a lo mencionado anteriormente del tamaño de las épocas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vecinos próximos </h3>\n",
    "<p style=\"font-size: medium\"> Para la segunda parte de vecinos próximos, ejecutaremos el método que nos proporciona Scikit-learn para este modelo: KNeighborsClassifier. Lo ejecutaremos para los mismos parametros que en nuestra implementación para poder compararlo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Validación Simple </h4>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Simple. </p>\n",
    "<p style=\"font-size: medium\">A continuación, utilizaremos el método KNeighborsClassifier. En este método iremos cambiando solo el valor de k, y utilizaremos solo las distancias euclídea y manhattan.</p>\n",
    "\n",
    "<h5> Indians </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksKnn = [3, 5]\n",
    "distanciasKnn = [\"euclidean\", \"manhattan\"]\n",
    "error_vs_i_knn = []\n",
    "data_vs_i_knn = []\n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        clasificador = neighbors.KNeighborsClassifier(n_neighbors = k, metric = dist)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_indians, y_indians, test_size=0.7)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_i_knn.append(1 - accuracy_score(y_test, predicciones))\n",
    "    data_vs_i_knn.append(error_vs_i_knn)\n",
    "    error_vs_i_knn = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_f84fa0ae_2f97_11eb_b020_6999629006a3row0_col0,#T_f84fa0ae_2f97_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_f84fa0ae_2f97_11eb_b020_6999629006a3row0_col1,#T_f84fa0ae_2f97_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 3</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.351301</td>\n",
       "                        <td id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.382900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.386617</td>\n",
       "                        <td id=\"T_f84fa0ae_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.351301</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ebc438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_vs_i_knn, columns=['k = 3', 'k = 5'],index=['Euclídea', 'Manhattan'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En este caso, los resultados están bastante igualados entre los valores de k, diría que entre esos dos valores cualquiera de los dos sería apropiado. Sin embargo, se debería escoger una k mayor para disminuir el error actual.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En cuanto a las distancias, podemos fácilmente ver que la euclídea es ligeramente mejor que la Manhattan.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC </h5>\n",
    "<p style=\"font-size: medium\">A continuación, utilizaremos el método KNeighborsClassifier. En este método iremos cambiando solo el valor de k.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vs_wdbc_knn = []\n",
    "data_vs_wdbc_knn = []\n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        clasificador = neighbors.KNeighborsClassifier(n_neighbors = k, metric = dist)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x_wdbc, y_wdbc, test_size=0.7)\n",
    "        clasificador.fit(x_train, y_train)\n",
    "        predicciones = clasificador.predict(x_test)\n",
    "        error_vs_wdbc_knn.append(1 - accuracy_score(y_test, predicciones))\n",
    "    data_vs_wdbc_knn.append(error_vs_wdbc_knn)\n",
    "    error_vs_wdbc_knn = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_fd34d508_2f97_11eb_b020_6999629006a3row0_col0,#T_fd34d508_2f97_11eb_b020_6999629006a3row1_col0{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }#T_fd34d508_2f97_11eb_b020_6999629006a3row0_col1,#T_fd34d508_2f97_11eb_b020_6999629006a3row1_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_fd34d508_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 3</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fd34d508_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_fd34d508_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.368421</td>\n",
       "                        <td id=\"T_fd34d508_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.380952</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fd34d508_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_fd34d508_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.365915</td>\n",
       "                        <td id=\"T_fd34d508_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.408521</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac60576d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_vs_wdbc_knn, columns=['k = 3', 'k = 5'],index=['Euclídea', 'Manhattan'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En primer lugar, podemos ver como los mejores resultados lo obtendríamos para un tamaño de vecindario de 5, con poca diferencia, pero definitivamente mejores. Para este caso, se podría coger una k mayor, pero no haría falta debido a que los errores ya son lo suficientemente bajos como para ser aceptables.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> Finalmente, la distancia con mejores resultados sería, al igual que en indians, la euclídea. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Validación Cruzada </h4>\n",
    "<p style=\"font-size: medium\">Ejecutaremos a continuación la estrategia de Validación Cruzada. </p>\n",
    "<p style=\"font-size: medium\">A continuación, utilizaremos el método KNeighborsClassifier. En este método iremos cambiando el valor de las disrancias, dejando un valor estable de k = 3</p>\n",
    "\n",
    "<h5> Indians </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanciasKnn = [\"euclidean\", \"manhattan\"]\n",
    "data_vc_i_knn = []\n",
    "error_vc_i_knn = []\n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        clasificador = neighbors.KNeighborsClassifier(n_neighbors = k, metric = dist)\n",
    "        cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "        error_vc_i_knn.append(np.mean(1 - model_selection.cross_val_score(clasificador, x_indians, y_indians, cv=cv)))\n",
    "    data_vc_i_knn.append(error_vc_i_knn)\n",
    "    error_vc_i_knn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vc_i_knn_mh = []\n",
    "for k in ksKnn:    \n",
    "    clasificador = neighbors.KNeighborsClassifier(n_neighbors = k, algorithm=\"brute\", metric = \"mahalanobis\", metric_params={'V': dataset.iloc[:,:-1].cov()})\n",
    "    cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "    error_vc_i_knn_mh.append(np.mean(1 - model_selection.cross_val_score(clasificador, x, y_indians, cv=cv)))\n",
    "\n",
    "data_vc_i_knn.append(error_vc_i_knn_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ff94643a_2f97_11eb_b020_6999629006a3row0_col0,#T_ff94643a_2f97_11eb_b020_6999629006a3row1_col1,#T_ff94643a_2f97_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_ff94643a_2f97_11eb_b020_6999629006a3row0_col1,#T_ff94643a_2f97_11eb_b020_6999629006a3row1_col0,#T_ff94643a_2f97_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ff94643a_2f97_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 3</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ff94643a_2f97_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.363636</td>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.334416</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ff94643a_2f97_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.379870</td>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.392857</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ff94643a_2f97_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >Mahalanobis</th>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.269481</td>\n",
       "                        <td id=\"T_ff94643a_2f97_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.272727</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac5ebf860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_vc_i_knn, columns=['k = 3', 'k = 5'],index=['Euclídea', 'Manhattan', 'Mahalanobis'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Observando el dataframe anterior, podemos ver fácilmente que el error más bajo está para k = 5. Nuevamente las diferencias entre las k son casi insignificantes y podrían considerarse nulas. Sin embargo, siendo estrictos, k = 5 es mejor sin duda que k = 3. </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En cuanto a las distancias, Mahalanobis parece tener una menor cantidad de errores en general. A diferencia de nuestra implementación, esta tarda muchísimo menos y no es tan costosa como lo es en nuestro código. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> WDBC </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanciasKnn = [\"euclidean\", \"manhattan\"]\n",
    "error_vc_wdbc_knn = []\n",
    "data_vc_wdbc_knn = []\n",
    "error_vc_wdbc_knn_mh = []\n",
    "for dist in distanciasKnn:\n",
    "    for k in ksKnn:\n",
    "        clasificador = neighbors.KNeighborsClassifier(n_neighbors = 3, metric = dist)\n",
    "        cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "        error_vc_wdbc_knn.append(np.mean(1 - model_selection.cross_val_score(clasificador, x_wdbc, y_wdbc, cv=cv)))\n",
    "    data_vc_wdbc_knn.append(error_vc_wdbc_knn)\n",
    "    error_vc_wdbc_knn = []\n",
    "    \n",
    "for k in ksKnn:\n",
    "    clasificador = neighbors.KNeighborsClassifier(n_neighbors = 3, metric = \"mahalanobis\", metric_params={'V': dataset2.iloc[:,:-1].cov()})\n",
    "    cv = model_selection.ShuffleSplit(n_splits=4)\n",
    "    error_vc_wdbc_knn_mh.append(np.mean(1 - model_selection.cross_val_score(clasificador, x2, y_wdbc, cv=cv)))\n",
    "data_vc_wdbc_knn.append(error_vc_wdbc_knn_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Resumen de lo medido </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_0d8c29ba_2f98_11eb_b020_6999629006a3row0_col0,#T_0d8c29ba_2f98_11eb_b020_6999629006a3row1_col1,#T_0d8c29ba_2f98_11eb_b020_6999629006a3row2_col0{\n",
       "            background-color:  #2575b7;\n",
       "            color:  #000000;\n",
       "        }#T_0d8c29ba_2f98_11eb_b020_6999629006a3row0_col1,#T_0d8c29ba_2f98_11eb_b020_6999629006a3row1_col0,#T_0d8c29ba_2f98_11eb_b020_6999629006a3row2_col1{\n",
       "            background-color:  #cee0f2;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >k = 3</th>        <th class=\"col_heading level0 col1\" >k = 5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3level0_row0\" class=\"row_heading level0 row0\" >Euclídea</th>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row0_col0\" class=\"data row0 col0\" >0.333333</td>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row0_col1\" class=\"data row0 col1\" >0.311404</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3level0_row1\" class=\"row_heading level0 row1\" >Manhattan</th>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row1_col0\" class=\"data row1 col0\" >0.289474</td>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row1_col1\" class=\"data row1 col1\" >0.333333</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3level0_row2\" class=\"row_heading level0 row2\" >Mahalanobis</th>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row2_col0\" class=\"data row2 col0\" >0.197368</td>\n",
       "                        <td id=\"T_0d8c29ba_2f98_11eb_b020_6999629006a3row2_col1\" class=\"data row2 col1\" >0.144737</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcac6057ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(data_vc_wdbc_knn, columns=['k = 3', 'k = 5'],index=['Euclídea', 'Manhattan', 'Mahalanobis'])\n",
    "resumen = resumen.style.background_gradient(cmap='Blues', low=.4, high=0.51, axis=1)\n",
    "display(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> En primer lugar, podemos observar como la mayoría de valores mínimos de error se dan para k =  3, a diferencia del dataset de Indians. Esto quiere decir que este dataset no necesita quitar del todo el ruído, o que, en realidad, no tiene tanto ruído y con un k ligeramente mayor a 1 puede clasificar correctamente. </p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En segundo lugar, si miramos las distancias podemos observar que nuevamente Mahalanobis vuelve a obtener menor error que el resto. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Análisis ROC </h2>\n",
    "<p style=\"font-size: medium\"> Para el análisis ROC utilizaremos nuestra implementación pero sin utilizar ningún tipo de estrategia de particionado. Incluiremos FPR y TPR de cada uno de los clasificadores discutidos en los apartados anteriores.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Obtención de los datos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('data/pima-indians-diabetes.data')\n",
    "dataset2 = Datos('data/wdbc.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> A continuación, los cálculos pertinentes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians dataset </h4>\n",
    "<p style=\"font-size: medium\">A continuación, calcularemos la matriz de confusión.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[421  79]\n",
      " [103 165]]\n"
     ]
    }
   ],
   "source": [
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "clasificador.entrenamiento(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "clases = list(dataset.datos.iloc[:, -1])\n",
    "matrix_i_nb = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_i_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR_i_nb = matrix_i_nb[0][1] / (matrix_i_nb[0][1] + matrix_i_nb[1][1])\n",
    "TPR_i_nb = matrix_i_nb[0][0] /(matrix_i_nb[0][0] + matrix_i_nb[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC dataset </h4>\n",
    "<p style=\"font-size: medium\">A continuación, calcularemos la matriz de confusión.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[344  13]\n",
      " [ 21 191]]\n"
     ]
    }
   ],
   "source": [
    "clasificador = ClasificadorNaiveBayes(False)\n",
    "clasificador.entrenamiento(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "clases = list(dataset2.datos.iloc[:, -1])\n",
    "matrix_w_nb = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_w_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR_w_nb = matrix_w_nb[0][1] / (matrix_w_nb[0][1] + matrix_w_nb[1][1])\n",
    "TPR_w_nb = matrix_w_nb[0][0] /(matrix_w_nb[0][0] + matrix_w_nb[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Regresión Logística </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[371 129]\n",
      " [ 84 184]]\n"
     ]
    }
   ],
   "source": [
    "clasificador = ClasificadorRegresionLogistica(10, 5)\n",
    "clasificador.entrenamiento(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "clases = list(dataset.datos.iloc[:, -1])\n",
    "matrix_i_rl = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_i_rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR_i_rl = matrix_i_rl[0][1] / (matrix_i_rl[0][1] + matrix_i_rl[1][1])\n",
    "TPR_i_rl = matrix_i_rl[0][0] /(matrix_i_rl[0][0] + matrix_i_rl[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355   2]\n",
      " [  8 204]]\n"
     ]
    }
   ],
   "source": [
    "clasificador = ClasificadorRegresionLogistica(10, 5)\n",
    "clasificador.entrenamiento(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "clases = list(dataset2.datos.iloc[:, -1])\n",
    "matrix_w_rl = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_w_rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR_w_rl = matrix_w_rl[0][1] / (matrix_w_rl[0][1] + matrix_w_rl[1][1])\n",
    "TPR_w_rl = matrix_w_rl[0][0] /(matrix_w_rl[0][0] + matrix_w_rl[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vecinos Próximos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indians dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[458  42]\n",
      " [ 72 196]]\n",
      "[[460  40]\n",
      " [ 76 192]]\n",
      "[[456  44]\n",
      " [ 76 192]]\n"
     ]
    }
   ],
   "source": [
    "# Euclídea\n",
    "clasificador = ClasificadorVecinosProximos(k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "clases = list(dataset.datos.iloc[:, -1])\n",
    "matrix_i_vp_e = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_i_vp_e)\n",
    "\n",
    "# Manhattan\n",
    "clasificador = ClasificadorVecinosProximos(distancia=\"manhattan\", k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "clases = list(dataset.datos.iloc[:, -1])\n",
    "matrix_i_vp_man = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_i_vp_man)\n",
    "\n",
    "# Mahalanobis\n",
    "clasificador = ClasificadorVecinosProximos(distancia=\"mahalanobis\", k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset.datos, dataset.nominalAtributos, dataset.diccionario)\n",
    "clases = list(dataset.datos.iloc[:, -1])\n",
    "matrix_i_vp_mah = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_i_vp_mah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclídea\n",
    "FPR_i_vp_e = matrix_i_vp_e[0][1] / (matrix_i_vp_e[0][1] + matrix_i_vp_e[1][1])\n",
    "TPR_i_vp_e = matrix_i_vp_e[0][0] /(matrix_i_vp_e[0][0] + matrix_i_vp_e[1][0])\n",
    "\n",
    "# Manhattan\n",
    "FPR_i_vp_man = matrix_i_vp_man[0][1] / (matrix_i_vp_man[0][1] + matrix_i_vp_man[1][1])\n",
    "TPR_i_vp_man = matrix_i_vp_man[0][0] /(matrix_i_vp_man[0][0] + matrix_i_vp_man[1][0])\n",
    "\n",
    "# Mahalanobis\n",
    "FPR_i_vp_mah = matrix_i_vp_mah[0][1] / (matrix_i_vp_mah[0][1] + matrix_i_vp_mah[1][1])\n",
    "TPR_i_vp_mah = matrix_i_vp_mah[0][0] /(matrix_i_vp_mah[0][0] + matrix_i_vp_mah[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> WDBC dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356   1]\n",
      " [ 10 202]]\n",
      "[[357   0]\n",
      " [  8 204]]\n",
      "[[355   2]\n",
      " [ 57 155]]\n"
     ]
    }
   ],
   "source": [
    "# Euclídea\n",
    "clasificador = ClasificadorVecinosProximos(k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "clases = list(dataset2.datos.iloc[:, -1])\n",
    "matrix_w_vp_e = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_w_vp_e)\n",
    "\n",
    "# Manhattan\n",
    "clasificador = ClasificadorVecinosProximos(distancia=\"manhattan\", k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "clases = list(dataset2.datos.iloc[:, -1])\n",
    "matrix_w_vp_man = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_w_vp_man)\n",
    "\n",
    "# Mahalanobis\n",
    "clasificador = ClasificadorVecinosProximos(distancia=\"mahalanobis\", k=3, normalizacion=True)\n",
    "clasificador.entrenamiento(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "predicciones = clasificador.clasifica(dataset2.datos, dataset2.nominalAtributos, dataset2.diccionario)\n",
    "clases = list(dataset2.datos.iloc[:, -1])\n",
    "matrix_w_vp_mah = confusion_matrix(y_true=clases, y_pred=predicciones)\n",
    "print(matrix_w_vp_mah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclídea\n",
    "FPR_w_vp_e = matrix_w_vp_e[0][1] / (matrix_w_vp_e[0][1] + matrix_w_vp_e[1][1])\n",
    "TPR_w_vp_e = matrix_w_vp_e[0][0] /(matrix_w_vp_e[0][0] + matrix_w_vp_e[1][0])\n",
    "\n",
    "# Manhattan\n",
    "FPR_w_vp_man = matrix_w_vp_man[0][1] / (matrix_w_vp_man[0][1] + matrix_w_vp_man[1][1])\n",
    "TPR_w_vp_man = matrix_w_vp_man[0][0] /(matrix_w_vp_man[0][0] + matrix_w_vp_man[1][0])\n",
    "\n",
    "# Mahalanobis\n",
    "FPR_w_vp_mah = matrix_w_vp_mah[0][1] / (matrix_w_vp_mah[0][1] + matrix_w_vp_mah[1][1])\n",
    "TPR_w_vp_mah = matrix_w_vp_mah[0][0] /(matrix_w_vp_mah[0][0] + matrix_w_vp_mah[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dibujamos el espacio ROC</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\">A continuación, calcularemos las tasas de FPR y TPR, que irán en el eje de las abscisas y eje de las ordenadas respectivamente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotteamos las gráficas\n",
    "\n",
    "plt.plot(FPR_i_nb, TPR_i_nb, color='red', marker='o', label='Indians (NB)')\n",
    "plt.plot(FPR_w_nb, TPR_w_nb, color='green', marker='o', label='WDBC (NB)')\n",
    "\n",
    "plt.plot(FPR_i_rl, TPR_i_rl, color='blue', marker='o', label='Indians (RL)')\n",
    "plt.plot(FPR_w_rl, TPR_w_rl, color='gray', marker='o', label='WDBC (RL)')\n",
    "\n",
    "plt.plot(FPR_i_vp_e, TPR_i_vp_e, color='purple', marker='o', label='Indians (VP-Euclídea)')\n",
    "plt.plot(FPR_i_vp_man, TPR_i_vp_man, color='cyan', marker='o', label='Indians (VP-Manhattan)')\n",
    "plt.plot(FPR_i_vp_mah, TPR_i_vp_mah, color='pink', marker='o', label='Indians (VP-Mahalanobis)')\n",
    "\n",
    "plt.plot(FPR_w_vp_e, TPR_w_vp_e, color='brown', marker='o', label='WDBC (VP-Euclídea)')\n",
    "plt.plot(FPR_w_vp_man, TPR_w_vp_man, color='black', marker='o', label='WDBC (VP-Manhattan)')\n",
    "plt.plot(FPR_w_vp_mah, TPR_w_vp_mah, color='magenta', marker='o', label='WDBC (VP-Mahalanobis)')\n",
    "\n",
    "plt.plot( [0,1],[0,1], ls='--') #Linea diagonal\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: medium\"> Podemos observar que para el dataset de indians se obtienen peores resultados que para el dataset de WDBC. Dentro de los Indians, tanto Naive Bayes y Regresión Logística tienen aproximadamente el mismo porcentaje de verdaderos positivos, pero el clasificador de Naive Bayes obtiene menos cantidad de falsos positivos que el de Regresión Logística. Por lo que podría decirse que Naive Bayes ligeramente más certero que Regresión Logística para este dataset. En cuanto a Vecinos Próximos, vemos que tiene muchísimos menos falsos positivos que los calsificadores anteriores. No cabe duda que el mismo se ajusta mucho mejor al dataset que Bayes y que Regresión.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En el caso del WDBC, observamos que el clasificador de Regresión Logística no solo obtiene más verdaderos positivos, sino que consigue menos falsos positivos, consiguiendo casi una clasificación perfecta, que el de Naive Bayes. Sin embargo, si comparamos regresión con vecinos próximos, vemos que este segundo es ligeramente mejor que el primero. Tiene menos falsos positivos que regresión y aparente estar ligeramente más alejado de la diagonal.</p>\n",
    "\n",
    "<p style=\"font-size: medium\"> En general, los tres modelos podrían considerarse adecuados para clasificar estos datasets, puesto que se posicionan por encima y alejados de la recta. Esto es debido a que mientras más alejados de la recta, más aumenta la sensibilidad y la especificidad del modelo. En el caso de caer sobre la recta significaría una clasificación completamente aleatoria, por lo que, al caer debajo de la recta significaría una clasificación peor que el azar.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
